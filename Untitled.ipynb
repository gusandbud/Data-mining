{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Using DictVectorizer, we enforce one-hot encoding on arrival cities,\n",
    "#      arrival airports, departure cities and departure airports\n",
    "def PreProc(df_set):\n",
    "    from sklearn import feature_extraction\n",
    "    dvec = feature_extraction.DictVectorizer()\n",
    "    cols = ['Departure','CityDeparture','Arrival','CityArrival']\n",
    "    mkdict = lambda row: dict((col, row[col]) for col in cols)\n",
    "    # one-hot encoded data replaces pre-existing columns\n",
    "    vecData = pd.DataFrame(dvec.fit_transform(df_train[cols].apply(mkdict,axis = 1)).toarray())\n",
    "    vecData.columns = dvec.get_feature_names()\n",
    "    vecData.index = df_train.index\n",
    "    df_set = pd.concat([df_set.drop(cols,axis = 1),vecData],axis = 1)\n",
    "    df_set = DateExtraColumns(df_set)\n",
    "    df_train = df_train.drop('DateOfDeparture', axis = 1)\n",
    "    return(df_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new column names are listed below\n",
    "# print(dvec.get_feature_names())\n",
    "#vecData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here, we examine the possibility of the dates having an impact on variable PAX.\n",
    "# In the next few functions,we analyze departure dates from different perspectives\n",
    "\n",
    "def DateExtraColumns(df_set):\n",
    "    df_set\n",
    "    dates = df_set['DateOfDeparture']\n",
    "    date_lambda = lambda row: (datetime.datetime.strptime(row, \"%Y-%m-%d\"))\n",
    "    df_dates = map(date_lambda,dates)\n",
    "    df_set = DayOfWeek(df_set,df_dates)\n",
    "    df_set = Seasons(df_set,df_dates)\n",
    "    df_set = IsNearChristmas(df_set,df_dates)\n",
    "    return(df_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Firstly, we divide dates by day of the week (0 for Monday,1 for Tuesday etc.)\n",
    "# We suspect more people should be travelling on end-of-the-week flights\n",
    "def DayOfWeeek(df_set,df_dates):\n",
    "    DOW_l = lambda row: (datetime.datetime.weekday(row))\n",
    "    day_of_week = map(DOW_l, df_dates)\n",
    "    day_of_week = pd.DataFrame(day_of_week)\n",
    "    day_of_week.columns = ['Day of week']\n",
    "    df_set = pd.concat([df_set,day_of_week],axis = 1)\n",
    "    return(df_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Next, we take into consideration what season trips take place in (Winter,Spring,Summer or Fall)\n",
    "# by one-hot encoding them\n",
    "def Seasons(df_set,df_dates):\n",
    "    from sklearn.preprocessing import OneHotEncoder as ohe\n",
    "\n",
    "    seasons = {\n",
    "        1 : 0,\n",
    "        2 : 0,\n",
    "        3 : 1,\n",
    "        4 : 1,\n",
    "        5 : 1,\n",
    "        6 : 2,\n",
    "        7 : 2,\n",
    "        8 : 2,\n",
    "        9 : 3,\n",
    "        10 : 3,\n",
    "        11 : 3,\n",
    "        12 : 0\n",
    "    }\n",
    "    date_by_season =  map(lambda x: seasons[x.month], df_dates)\n",
    "    date_by_season = pd.DataFrame(date_by_season)\n",
    "    date_by_season.columns = ['Season']\n",
    "    enc = ohe(sparse=False)\n",
    "    enc.fit(date_by_season)\n",
    "    date_by_season = enc.transform(date_by_season)\n",
    "    date_by_season = pd.DataFrame(date_by_season)\n",
    "    date_by_season.columns = ['Winter','Spring','Summer','Fall']\n",
    "    df_set = pd.concat([df_set, date_by_season],axis = 1)\n",
    "    return(df_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Another, more specific, time of year that we expect flights to be crowded\n",
    "# would be around Christmas and New year. Therefore, we determine whether a flight\n",
    "# took place between the 15th of December and the 10th of January (dates determined at random around\n",
    "# the specified holidays)\n",
    "def IsNearChristmas(df_set,df_dates):\n",
    "    around_christmas = map(lambda x: (int)(((x.month == 12) and (x.day >= 15)) or\n",
    "                          (x.month == 1 and x.day <= 10)), df_dates)\n",
    "    around_christmas\n",
    "    around_christmas = pd.DataFrame(around_christmas)\n",
    "    around_christmas.columns = ['IsAroundChristmas']\n",
    "    df_set = pd.concat([df_set, around_christmas], axis = 1)\n",
    "    return(df_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DecisionTreeClassifierEntropyTestOnly(train_set):\n",
    "    from sklearn import tree\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    df_target = train_set['PAX']\n",
    "    df_data = train_set.drop('PAX', axis = 1)\n",
    "    df1_train,df1_test,df2_train,df2_test = train_test_split(df_data,df_target,test_size = 0.2,random_state = 42)\n",
    "    dt = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "    dt = dt.fit(df1_train,df2_train)\n",
    "    from sklearn import metrics\n",
    "    df2_pred = dt.predict(df1_test)\n",
    "    #print \"Accuracy:{0:.14f}\".format(metrics.f1_score(df2_test,df2_pred)),\"\\n\"\n",
    "    return(df2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DecisionTreeClassifierEntropy(train_set,test_set):\n",
    "    from sklearn import tree\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    df_target = train_set['PAX']\n",
    "    df_data = train_set.drop('PAX', axis = 1)\n",
    "    df1_train,df1_test,df2_train,df2_test = train_test_split(df_data,df_target,test_size = 0.2,random_state = 42)\n",
    "    dt = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "    dt = dt.fit(df1_train,df2_train)\n",
    "    from sklearn import metrics\n",
    "    df2_pred = dt.predict(df1_test)\n",
    "    #print \"Accuracy:{0:.14f}\".format(metrics.f1_score(df2_test,df2_pred)),\"\\n\"\n",
    "    return(df2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.parser import parse\n",
    "import datetime\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_train = PreProc(df_train)\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_test = PrePreoc(df_test)\n",
    "\n",
    "y_pred = DecisionTreeClassifierEntropy(df_train,df_test)\n",
    "#np.savetxt('y_pred.txt', y_pred, fmt='%d')\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Departure</th>\n",
       "      <th>CityDeparture</th>\n",
       "      <th>LongitudeDeparture</th>\n",
       "      <th>LatitudeDeparture</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>CityArrival</th>\n",
       "      <th>LongitudeArrival</th>\n",
       "      <th>LatitudeArrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>std_wtd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-21</td>\n",
       "      <td>DFW</td>\n",
       "      <td>Dallas-Fort Worth</td>\n",
       "      <td>32.896828</td>\n",
       "      <td>-97.037997</td>\n",
       "      <td>SFO</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>37.618972</td>\n",
       "      <td>-122.374889</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>11.575837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-13</td>\n",
       "      <td>LAX</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>33.942536</td>\n",
       "      <td>-118.408075</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>33.636719</td>\n",
       "      <td>-84.428067</td>\n",
       "      <td>14.730769</td>\n",
       "      <td>13.364304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>41.978603</td>\n",
       "      <td>-87.904842</td>\n",
       "      <td>IAH</td>\n",
       "      <td>Houston</td>\n",
       "      <td>29.984433</td>\n",
       "      <td>-95.341442</td>\n",
       "      <td>8.470588</td>\n",
       "      <td>5.885551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-08-13</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Denver</td>\n",
       "      <td>39.861656</td>\n",
       "      <td>-104.673178</td>\n",
       "      <td>PHX</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>33.434278</td>\n",
       "      <td>-112.011583</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>6.292853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>ORD</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>41.978603</td>\n",
       "      <td>-87.904842</td>\n",
       "      <td>SEA</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>47.449000</td>\n",
       "      <td>-122.309306</td>\n",
       "      <td>12.090909</td>\n",
       "      <td>9.138662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DateOfDeparture Departure      CityDeparture  LongitudeDeparture  \\\n",
       "0      2012-10-21       DFW  Dallas-Fort Worth           32.896828   \n",
       "1      2012-09-13       LAX        Los Angeles           33.942536   \n",
       "2      2012-09-04       ORD            Chicago           41.978603   \n",
       "3      2012-08-13       DEN             Denver           39.861656   \n",
       "4      2012-09-10       ORD            Chicago           41.978603   \n",
       "\n",
       "   LatitudeDeparture Arrival    CityArrival  LongitudeArrival  \\\n",
       "0         -97.037997     SFO  San Francisco         37.618972   \n",
       "1        -118.408075     ATL        Atlanta         33.636719   \n",
       "2         -87.904842     IAH        Houston         29.984433   \n",
       "3        -104.673178     PHX        Phoenix         33.434278   \n",
       "4         -87.904842     SEA        Seattle         47.449000   \n",
       "\n",
       "   LatitudeArrival  WeeksToDeparture    std_wtd  \n",
       "0      -122.374889         14.600000  11.575837  \n",
       "1       -84.428067         14.730769  13.364304  \n",
       "2       -95.341442          8.470588   5.885551  \n",
       "3      -112.011583          8.200000   6.292853  \n",
       "4      -122.309306         12.090909   9.138662  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X must be non-negative.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-403eb2e0e59a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfeature_selection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSelectPercentile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchi2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpercentile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train_fs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf2_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Konstantinos-Anastas\\Anaconda2\\lib\\site-packages\\sklearn\\base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Konstantinos-Anastas\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Konstantinos-Anastas\\Anaconda2\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.pyc\u001b[0m in \u001b[0;36mchi2\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input X must be non-negative.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input X must be non-negative."
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import feature_selection\n",
    "fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile = 20)\n",
    "X_train_fs = fs.fit_transform(df1_train,df2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train['Departure'])\n",
    "df_train['Departure'] = le.transform(df_train['Departure'])\n",
    "df_train['Arrival'] = le.transform(df_train['Arrival'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arrival=ATL</th>\n",
       "      <th>Arrival=BOS</th>\n",
       "      <th>Arrival=CLT</th>\n",
       "      <th>Arrival=DEN</th>\n",
       "      <th>Arrival=DFW</th>\n",
       "      <th>Arrival=DTW</th>\n",
       "      <th>Arrival=EWR</th>\n",
       "      <th>Arrival=IAH</th>\n",
       "      <th>Arrival=JFK</th>\n",
       "      <th>Arrival=LAS</th>\n",
       "      <th>...</th>\n",
       "      <th>Departure=PHL</th>\n",
       "      <th>Departure=PHX</th>\n",
       "      <th>Departure=SEA</th>\n",
       "      <th>Departure=SFO</th>\n",
       "      <th>LatitudeArrival</th>\n",
       "      <th>LatitudeDeparture</th>\n",
       "      <th>LongitudeArrival</th>\n",
       "      <th>LongitudeDeparture</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>std_wtd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7104.000000</td>\n",
       "      <td>7104.000000</td>\n",
       "      <td>7104.000000</td>\n",
       "      <td>7104.000000</td>\n",
       "      <td>7104.000000</td>\n",
       "      <td>7104.000000</td>\n",
       "      <td>7104.000000</td>\n",
       "      <td>7104.000000</td>\n",
       "      <td>7104.000000</td>\n",
       "      <td>7104.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7104.000000</td>\n",
       "      <td>7104.000000</td>\n",
       "      <td>7104.000000</td>\n",
       "      <td>7104.000000</td>\n",
       "      <td>7134.000000</td>\n",
       "      <td>7134.000000</td>\n",
       "      <td>7134.000000</td>\n",
       "      <td>7134.00000</td>\n",
       "      <td>7134.000000</td>\n",
       "      <td>7134.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.113880</td>\n",
       "      <td>0.067849</td>\n",
       "      <td>0.014640</td>\n",
       "      <td>0.073198</td>\n",
       "      <td>0.064189</td>\n",
       "      <td>0.022523</td>\n",
       "      <td>0.045749</td>\n",
       "      <td>0.016329</td>\n",
       "      <td>0.030405</td>\n",
       "      <td>0.049409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.015203</td>\n",
       "      <td>0.031813</td>\n",
       "      <td>0.075591</td>\n",
       "      <td>-93.703171</td>\n",
       "      <td>-93.452752</td>\n",
       "      <td>37.674883</td>\n",
       "      <td>37.80124</td>\n",
       "      <td>11.447798</td>\n",
       "      <td>8.613036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.317687</td>\n",
       "      <td>0.251504</td>\n",
       "      <td>0.120114</td>\n",
       "      <td>0.260480</td>\n",
       "      <td>0.245107</td>\n",
       "      <td>0.148386</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.126746</td>\n",
       "      <td>0.171712</td>\n",
       "      <td>0.216735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196909</td>\n",
       "      <td>0.122367</td>\n",
       "      <td>0.175514</td>\n",
       "      <td>0.264362</td>\n",
       "      <td>17.511743</td>\n",
       "      <td>17.428464</td>\n",
       "      <td>4.704637</td>\n",
       "      <td>4.67581</td>\n",
       "      <td>2.791529</td>\n",
       "      <td>2.142945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-122.374889</td>\n",
       "      <td>-122.374889</td>\n",
       "      <td>25.793250</td>\n",
       "      <td>25.79325</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>2.160247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-71.005181</td>\n",
       "      <td>-71.005181</td>\n",
       "      <td>47.449000</td>\n",
       "      <td>47.44900</td>\n",
       "      <td>21.933333</td>\n",
       "      <td>15.862216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Arrival=ATL  Arrival=BOS  Arrival=CLT  Arrival=DEN  Arrival=DFW  \\\n",
       "count  7104.000000  7104.000000  7104.000000  7104.000000  7104.000000   \n",
       "mean      0.113880     0.067849     0.014640     0.073198     0.064189   \n",
       "std       0.317687     0.251504     0.120114     0.260480     0.245107   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%            NaN          NaN          NaN          NaN          NaN   \n",
       "50%            NaN          NaN          NaN          NaN          NaN   \n",
       "75%            NaN          NaN          NaN          NaN          NaN   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       Arrival=DTW  Arrival=EWR  Arrival=IAH  Arrival=JFK  Arrival=LAS  \\\n",
       "count  7104.000000  7104.000000  7104.000000  7104.000000  7104.000000   \n",
       "mean      0.022523     0.045749     0.016329     0.030405     0.049409   \n",
       "std       0.148386     0.208955     0.126746     0.171712     0.216735   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%            NaN          NaN          NaN          NaN          NaN   \n",
       "50%            NaN          NaN          NaN          NaN          NaN   \n",
       "75%            NaN          NaN          NaN          NaN          NaN   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "          ...       Departure=PHL  Departure=PHX  Departure=SEA  \\\n",
       "count     ...         7104.000000    7104.000000    7104.000000   \n",
       "mean      ...            0.040400       0.015203       0.031813   \n",
       "std       ...            0.196909       0.122367       0.175514   \n",
       "min       ...            0.000000       0.000000       0.000000   \n",
       "25%       ...                 NaN            NaN            NaN   \n",
       "50%       ...                 NaN            NaN            NaN   \n",
       "75%       ...                 NaN            NaN            NaN   \n",
       "max       ...            1.000000       1.000000       1.000000   \n",
       "\n",
       "       Departure=SFO  LatitudeArrival  LatitudeDeparture  LongitudeArrival  \\\n",
       "count    7104.000000      7134.000000        7134.000000       7134.000000   \n",
       "mean        0.075591       -93.703171         -93.452752         37.674883   \n",
       "std         0.264362        17.511743          17.428464          4.704637   \n",
       "min         0.000000      -122.374889        -122.374889         25.793250   \n",
       "25%              NaN              NaN                NaN               NaN   \n",
       "50%              NaN              NaN                NaN               NaN   \n",
       "75%              NaN              NaN                NaN               NaN   \n",
       "max         1.000000       -71.005181         -71.005181         47.449000   \n",
       "\n",
       "       LongitudeDeparture  WeeksToDeparture      std_wtd  \n",
       "count          7134.00000       7134.000000  7134.000000  \n",
       "mean             37.80124         11.447798     8.613036  \n",
       "std               4.67581          2.791529     2.142945  \n",
       "min              25.79325          2.625000     2.160247  \n",
       "25%                   NaN               NaN          NaN  \n",
       "50%                   NaN               NaN          NaN  \n",
       "75%                   NaN               NaN          NaN  \n",
       "max              47.44900         21.933333    15.862216  \n",
       "\n",
       "[8 rows x 84 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(df_train['CityDeparture'])\n",
    "df_train['CityDeparture'] = le.transform(df_train['CityDeparture'])\n",
    "df_train['CityArrival'] = le.transform(df_train['CityArrival'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for float(): 2012-07-20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4b22f851c901>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'entropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf2_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Konstantinos-Anastas\\Anaconda2\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Konstantinos-Anastas\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    371\u001b[0m                                       force_all_finite)\n\u001b[1;32m    372\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for float(): 2012-07-20"
     ]
    }
   ],
   "source": [
    "le.fit(df_train['DateOfDeparture'])\n",
    "df_train['DateOfDeparture'] = le.transform(df_train['DateOfDeparture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop('DateOfDeparture', axis = 1)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "df_target = df_train['PAX']\n",
    "df_data = df_train.drop('PAX', axis = 1)\n",
    "df1_train,df1_test,df2_train,df2_test = train_test_split(df_data,df_target,test_size = 0.2,random_state = 33)\n",
    "print ('Ths manas sou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import feature_selection\n",
    "fs = feature_selection.SelectPercentile(feature_selection.chi2, percentile = 5)\n",
    "X_train_fs = fs.fit_transform(df1_train,df2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-84146171cf17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
